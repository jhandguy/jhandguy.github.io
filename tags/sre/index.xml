<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SRE on jhandguy</title>
    <link>https://jhandguy.github.io/tags/sre/</link>
    <description>Recent content in SRE on jhandguy</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Feb 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://jhandguy.github.io/tags/sre/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Farewell, ECS! Hello, EKS: A Kubernetes Migration Story</title>
      <link>https://jhandguy.github.io/posts/farewell-ecs-hello-eks/</link>
      <pubDate>Wed, 28 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://jhandguy.github.io/posts/farewell-ecs-hello-eks/</guid>
      <description>&lt;p&gt;Saying goodbye to old systems can sound scary, but for us at EGYM, migrating from Elastic Container Service (ECS) to Elastic Kubernetes Service (EKS) was a journey of growth and excitement.&lt;/p&gt;&#xA;&lt;p&gt;ðŸŽ¬ Hi there, Iâ€™m Jean!&lt;/p&gt;&#xA;&lt;p&gt;In this blog post, Iâ€™ll share the inside scoop on our successful migration from ECS to EKS, why we did it and how, complete with the magic formula for &lt;strong&gt;zero downtime&lt;/strong&gt;!&lt;/p&gt;&#xA;&lt;h2 id=&#34;starting-with-the-why&#34;&gt;Starting with the Why&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Letâ€™s kick it off with a famous phrase in engineering:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vertical Pod Autoscaler in Kubernetes</title>
      <link>https://jhandguy.github.io/posts/vertical-pod-autoscaler/</link>
      <pubDate>Tue, 08 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://jhandguy.github.io/posts/vertical-pod-autoscaler/</guid>
      <description>&lt;p&gt;In Kubernetes, we usually think about the Horizontal Pod Autoscaler (HPA) when referring to autoscaling. In most cases, it will be the preferred way of scaling services, based on CPU usage, memory usage, or custom metrics.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;If you haven&amp;rsquo;t already, go read &lt;a href=&#34;https://jhandguy.github.io/posts/simple-horizontal-autoscaling/&#34;&gt;Horizontal Pod Autoscaler in Kubernetes (Part 1) - Simple Autoscaling using Metrics Server&lt;/a&gt; and learn how to implement a Horizontal Pod Autoscaler using Metrics Server!&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;However, while HPA can scale up and down replicas based on the current load, it is not capable of optimizing resource usage over the long term:  This is where the Vertical Pod Autoscaler (VPA) comes in.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Horizontal Pod Autoscaler in Kubernetes (Part 2) â€” Advanced Autoscaling using Prometheus Adapter</title>
      <link>https://jhandguy.github.io/posts/advanced-horizontal-autoscaling/</link>
      <pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://jhandguy.github.io/posts/advanced-horizontal-autoscaling/</guid>
      <description>&lt;p&gt;The Horizontal Pod Autoscaler (HPA) is a fundamental feature of Kubernetes. It enables automatic scale-up and scale-down of containerized applications based on CPU usage, memory usage, or custom metrics.&lt;/p&gt;&#xA;&lt;p&gt;Traditionally, when scaling software, we first think of vertical scaling: the CPU and the RAM are increased so the application consuming them can perform better. While this seems like a flawless mechanism on paper, it actually comes with many drawbacks.&lt;/p&gt;&#xA;&lt;p&gt;First, upgrading the CPU or RAM on a physical machine (or VM) requires downtime and unless a Pod Disruption Budget (PDB) is used to handle &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/disruptions&#34;&gt;disruptions&lt;/a&gt;, all pods will be evicted and recreated in the new resized node.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Horizontal Pod Autoscaler in Kubernetes (Part 1) â€” Simple Autoscaling using Metrics Server</title>
      <link>https://jhandguy.github.io/posts/simple-horizontal-autoscaling/</link>
      <pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://jhandguy.github.io/posts/simple-horizontal-autoscaling/</guid>
      <description>&lt;p&gt;The Horizontal Pod Autoscaler (HPA) is a fundamental feature of Kubernetes. It enables automatic scale-up and scale-down of containerized applications based on CPU usage, memory usage, or custom metrics.&lt;/p&gt;&#xA;&lt;p&gt;Traditionally, when scaling software, we first think of vertical scaling: the CPU and the RAM are increased so the application consuming them can perform better. While this seems like a flawless mechanism on paper, it actually comes with many drawbacks.&lt;/p&gt;&#xA;&lt;p&gt;First, upgrading the CPU or RAM on a physical machine (or VM) requires downtime and unless a Pod Disruption Budget (PDB) is used to handle &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/disruptions&#34;&gt;disruptions&lt;/a&gt;, all pods will be evicted and recreated in the new resized node.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Incremental Mobile Force Update using Ingress NGINX and Firebase Remote Config</title>
      <link>https://jhandguy.github.io/posts/incremental-mobile-force-update/</link>
      <pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://jhandguy.github.io/posts/incremental-mobile-force-update/</guid>
      <description>&lt;p&gt;Mobile &lt;a href=&#34;https://betterprogramming.pub/force-update-your-apps-74de57523650&#34;&gt;force updates&lt;/a&gt; occur when old versions of an app are no longer compatible with the APIs they consume.&#xA;Until the app is updated to the required version, the UI blocks further usage.&#xA;This is usually materialized as a system popup that will redirect users to the respective Store and disappear only once they have updated to the latest version.&#xA;This is often considered bad practice as it deteriorates the UX of an app drastically, yet there are situations (mostly breaking API changes) when it is unavoidable.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Canary Deployment in Kubernetes (Part 3) â€” Smart Canary Deployment using Argo Rollouts and Prometheus</title>
      <link>https://jhandguy.github.io/posts/smart-canary-deployment/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://jhandguy.github.io/posts/smart-canary-deployment/</guid>
      <description>&lt;p&gt;Deploying to production in Kubernetes can be quite stressful. Even after meaningful and reliable automated tests have successfully passed, there is still room for things to go wrong and lead to a nasty incident when pressing the final button.&lt;/p&gt;&#xA;&lt;p&gt;Thankfully, Kubernetes is made to be resilient to this kind of scenario, and rolling back is a no-brainer. But still, rolling back means that, at least for some time, &lt;strong&gt;all of the users&lt;/strong&gt; were negatively impacted by the faulty changeâ€¦&lt;/p&gt;</description>
    </item>
    <item>
      <title>Canary Deployment in Kubernetes (Part 2) â€” Automated Canary Deployment using Argo Rollouts</title>
      <link>https://jhandguy.github.io/posts/automated-canary-deployment/</link>
      <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://jhandguy.github.io/posts/automated-canary-deployment/</guid>
      <description>&lt;p&gt;Deploying to production in Kubernetes can be quite stressful. Even after meaningful and reliable automated tests have successfully passed, there is still room for things to go wrong and lead to a nasty incident when pressing the final button.&lt;/p&gt;&#xA;&lt;p&gt;Thankfully, Kubernetes is made to be resilient to this kind of scenario, and rolling back is a no-brainer. But still, rolling back means that, at least for some time, &lt;strong&gt;all of the users&lt;/strong&gt; were negatively impacted by the faulty changeâ€¦&lt;/p&gt;</description>
    </item>
    <item>
      <title>Canary Deployment in Kubernetes (Part 1) â€” Simple Canary Deployment using Ingress NGINX</title>
      <link>https://jhandguy.github.io/posts/simple-canary-deployment/</link>
      <pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://jhandguy.github.io/posts/simple-canary-deployment/</guid>
      <description>&lt;p&gt;Deploying to production in Kubernetes can be quite stressful. Even after meaningful and reliable automated tests have successfully passed, there is still room for things to go wrong and lead to a nasty incident when pressing the final button.&lt;/p&gt;&#xA;&lt;p&gt;Thankfully, Kubernetes is made to be resilient to this kind of scenario, and rolling back is a no-brainer. But still, rolling back means that, at least for some time, &lt;strong&gt;all of the users&lt;/strong&gt; were negatively impacted by the faulty changeâ€¦&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
