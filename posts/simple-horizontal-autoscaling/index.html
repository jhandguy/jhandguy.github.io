<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Horizontal Pod Autoscaler in Kubernetes (Part 1) ‚Äî Simple Autoscaling using Metrics Server</title>
    <link rel="stylesheet" href="/css/bulma.min.css">
    <link rel="stylesheet" href="/css/custom.css">
</head>
<body>
<nav class="navbar">
    <div class="navbar-brand">
        <a class="navbar-item" href="/">
            Home
        </a>
        <div class="navbar-item">
            <a class="button is-link" href="/about">
                <strong>About me</strong>
            </a>
        </div>
    </div>
</nav>

<section class="section">
    <div class="container is-max-desktop">
        <div class="content">
            <p class="title is-spaced">Horizontal Pod Autoscaler in Kubernetes (Part 1) ‚Äî Simple Autoscaling using Metrics Server</p>
            
            
            <div class="box">
                <p class="subtitle">Table of Contents</p>
                <nav id="TableOfContents">
  <ul>
    <li><a href="#requirements">Requirements</a></li>
    <li><a href="#creating-kind-cluster">Creating Kind Cluster</a></li>
    <li><a href="#installing-nginx-ingress-controller">Installing NGINX Ingress Controller</a></li>
    <li><a href="#installing-metrics-server">Installing Metrics Server</a></li>
    <li><a href="#horizontal-pod-autoscaler">Horizontal Pod Autoscaler</a></li>
    <li><a href="#autoscaling-native-services-based-on-cpu-and-memory-usage">Autoscaling Native Services based on CPU and Memory Usage</a></li>
    <li><a href="#autoscaling-jvm-services-based-on-cpu-usage">Autoscaling JVM Services based on CPU Usage</a></li>
    <li><a href="#wrapping-up">Wrapping up</a></li>
  </ul>
</nav>
            </div>
            
            
        </div>
    </div>
    <div class="container is-max-desktop mt-6">
        <div class="content has-text-justified-tablet">
            <p>The Horizontal Pod Autoscaler (HPA) is a fundamental feature of Kubernetes. It enables automatic scale-up and scale-down of containerized applications based on CPU usage, memory usage, or custom metrics.</p>
<p>Traditionally, when scaling software, we first think of vertical scaling: the CPU and the RAM are increased so the application consuming them can perform better. While this seems like a flawless mechanism on paper, it actually comes with many drawbacks.</p>
<p>First, upgrading the CPU or RAM on a physical machine (or VM) requires downtime and unless a Pod Disruption Budget (PDB) is used to handle <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions">disruptions</a>, all pods will be evicted and recreated in the new resized node.</p>
<p>Nodes resource usage is also not optimized, as scaling vertically means requiring sufficient resources in a single node, while horizontal scaling may have the same amount of resources distributed across multiple nodes.</p>
<p>Additionally, vertical scaling is not as resilient as horizontal scaling, as fewer replicas mean higher risks of disruptions in case of node failure.</p>
<p>Finally, reaching a certain threshold, scaling only vertically becomes very expensive and most importantly, isn‚Äôt limitless. In fact, there is only so much CPU and RAM a physical machine(or VM) alone can handle.<br>
This is where horizontal scaling comes into play!</p>
<blockquote>
<p>Eventually, it is more efficient to duplicate an instance, than increase its resources.</p></blockquote>
<p>üé¨ Hi there, I&rsquo;m Jean!</p>
<p>In this 2 parts series, we&rsquo;re going to explore several ways to scale services horizontally in Kubernetes, and the first one is‚Ä¶<br>
ü•Å<br>
‚Ä¶ using <strong>Metrics Server</strong>! üéä</p>
<h2 id="requirements">Requirements</h2>
<hr>
<p>Before we start, make sure you have the following tools installed:</p>
<ul>
<li><a href="https://kind.sigs.k8s.io/docs/user/quick-start/#installation">Kind</a></li>
<li><a href="https://kubernetes.io/docs/tasks/tools/">Kubectl</a></li>
<li><a href="https://helm.sh/docs/intro/install/">Helm</a></li>
<li><a href="https://grafana.com/docs/k6/latest/set-up/install-k6/">K6</a></li>
</ul>
<blockquote>
<p><em>Note: for MacOS users or Linux users using Homebrew, simply run:</em><br>
<code>brew install kind kubectl helm k6</code></p></blockquote>
<p>All set? Let‚Äôs go! üèÅ</p>
<h2 id="creating-kind-cluster">Creating Kind Cluster</h2>
<hr>
<p><a href="https://kind.sigs.k8s.io/">Kind</a> is a tool for running local Kubernetes clusters using Docker container ‚Äúnodes‚Äù.
It was primarily designed for testing Kubernetes itself, but may be used for local development or CI.</p>
<p>I don‚Äôt expect you to have a demo project in handy, so <a href="https://github.com/jhandguy/canary-deployment">I built one</a> for you.</p>
<pre><code class="language-shell">git clone https://github.com/jhandguy/horizontal-pod-autoscaler.git
cd horizontal-pod-autoscaler
</code></pre>
<p>Alright, let&rsquo;s spin up our Kind cluster! üöÄ</p>
<pre><code class="language-shell">‚ûú kind create cluster --image kindest/node:v1.27.3 --config=kind/cluster.yaml
Creating cluster &quot;kind&quot; ...
 ‚úì Ensuring node image (kindest/node:v1.27.3) üñº
 ‚úì Preparing nodes üì¶
 ‚úì Writing configuration üìú
 ‚úì Starting control-plane üïπÔ∏è
 ‚úì Installing CNI üîå
 ‚úì Installing StorageClass üíæ
Set kubectl context to &quot;kind-kind&quot;
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community üôÇ
</code></pre>
<h2 id="installing-nginx-ingress-controller">Installing NGINX Ingress Controller</h2>
<hr>
<p><a href="https://github.com/kubernetes/ingress-nginx">NGINX Ingress Controller</a> is one of the <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/#additional-controllers">many available Kubernetes Ingress Controllers</a>, which acts as a load balancer and satisfies routing rules specified in <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/#what-is-ingress">Ingress</a> resources, using the <a href="https://nginx.org/en/">NGINX reverse proxy</a>.</p>
<p>NGINX Ingress Controller can be installed via its <a href="https://github.com/kubernetes/ingress-nginx/tree/main/charts/ingress-nginx">Helm chart</a>.</p>
<pre><code class="language-shell">helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install ingress-nginx/ingress-nginx --name-template ingress-nginx --create-namespace -n ingress-nginx --values kind/ingress-nginx-values.yaml --version 4.8.3 --wait
</code></pre>
<p>Now, if everything goes according to plan, you should be able to see the <strong>ingress-nginx-controller</strong> Deployment running.</p>
<pre><code class="language-shell">‚ûú kubectl get deploy -n ingress-nginx
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
ingress-nginx-controller   1/1     1            1           4m35s
</code></pre>
<h2 id="installing-metrics-server">Installing Metrics Server</h2>
<hr>
<p><a href="https://github.com/kubernetes-sigs/metrics-server">Metrics Server</a> is a source of container resource metrics, which collects them from Kubelets and exposes them in Kubernetes API server through <a href="https://github.com/kubernetes/metrics">Metrics API</a> for use by <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler</a> and <a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/">Vertical Pod Autoscaler</a>.</p>
<p>Metrics Server can be installed via its <a href="https://github.com/kubernetes-sigs/metrics-server/tree/master/charts/metrics-server">Helm chart</a>.</p>
<pre><code class="language-shell">helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server
helm install metrics-server/metrics-server --name-template metrics-server --create-namespace -n metrics-server --values kind/metrics-server-values.yaml --version 3.11.0 --wait
</code></pre>
<p>Now, if everything goes according to plan, you should be able to see the <strong>metrics-server</strong> Deployment running.</p>
<pre><code class="language-shell">‚ûú kubectl get deploy -n metrics-server
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
metrics-server   1/1     1            1           38s
</code></pre>
<h2 id="horizontal-pod-autoscaler">Horizontal Pod Autoscaler</h2>
<hr>
<p>Before we dive in, let&rsquo;s quickly remind ourselves of what a <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">Horizontal Pod Autoscaler</a> in Kubernetes actually is:</p>
<blockquote>
<p><em>A <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">HorizontalPodAutoscaler</a> (HPA for short) automatically updates a workload resource (such as a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Deployment</a> or <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">StatefulSet</a>), with the aim of automatically scaling the workload to match demand.</em><br>
<em>Horizontal scaling means that the response to increased load is to deploy more <a href="https://kubernetes.io/docs/concepts/workloads/pods/">Pods</a>. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.</em><br>
<em>If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.</em></p></blockquote>
<p>Now that we know what an HPA is, let&rsquo;s get started, shall we? üßê</p>
<h2 id="autoscaling-native-services-based-on-cpu-and-memory-usage">Autoscaling Native Services based on CPU and Memory Usage</h2>
<hr>
<p>A native service is a piece  of software that does not require a virtual environment in order to run across different OSs and CPU architectures. This is the case  for C/C++, Golang, Rust, and more: those are languages that compile into a binary, that is directly executable by the Pod.<br>
This means that native services can utilize all of the CPU and memory  available from the Pod they run in, without an intermediary environment.</p>
<p>Let&rsquo;s try it out with a Golang service!</p>
<pre><code class="language-shell">helm install golang-sample-app/helm-chart --name-template sample-app --create-namespace -n sample-app --wait
</code></pre>
<p>If everything goes fine, you should eventually see one Deployment with the READY state.</p>
<pre><code class="language-shell">‚ûú kubectl get deploy -n sample-app
NAME         READY   UP-TO-DATE   AVAILABLE   AGE
sample-app   2/2     2            2           44s
</code></pre>
<p>Once the Pods are running, Metrics Server will start collecting the Pods resource metrics from the node&rsquo;s Kubelet and expose them in Kubernetes through <a href="https://github.com/kubernetes/metrics">Metrics API</a> for use by <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler</a> and <a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/">Vertical Pod Autoscaler</a>.</p>
<p>Let&rsquo;s see what the resource usage for those Pods currently is!</p>
<pre><code class="language-shell">‚ûú kubectl top pods -n sample-app
NAME                          CPU(cores)   MEMORY(bytes)
sample-app-6bcbfc8b49-j6xmq   1m           1Mi
sample-app-6bcbfc8b49-wtd8g   1m           1Mi
</code></pre>
<p>Pretty low, right? ü§î<br>
This is obviously expected since our Go service currently isn&rsquo;t handling any load.</p>
<p>Alright, now let&rsquo;s have a look at the HPA!</p>
<pre><code class="language-shell">‚ûú kubectl describe hpa -n sample-app
...
Metrics: ( current / target )
  resource memory on pods (as a percentage of request):  8% / 50%
  resource cpu on pods (as a percentage of request):     10% / 50%
Min replicas:                                            2
Max replicas:                                            8
...
</code></pre>
<p>As you can see, this HPA is configured to scale the service based on both CPU and memory, with average utilization of <strong>50%</strong> each.</p>
<p>This means that as soon as either the CPU or memory utilization breaches the <strong>50%</strong> threshold, the HPA will trigger an upscale.</p>
<p>Under minimal load, the HPA will still retain a replica count of <strong>2</strong>, while the maximum amount of Pods the HPA is allowed to spin up under high load is <strong>8</strong>.</p>
<blockquote>
<p><em>Note: in a production environment, it is recommended to have a minimum replica count of at least 3, to guarantee maintained availability in the case of <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/_print/#pod-disruption">Pod Disruption</a>.</em></p></blockquote>
<p>Now, this is the moment you&rsquo;ve certainly expected‚Ä¶ It&rsquo;s Load Testing time! üòé</p>
<p>For Load Testing, I really recommend <a href="https://grafana.com/docs/k6/latest/">k6</a> from the Grafana Labs team. It is a dead-simple yet super powerful tool with very extensive documentation.</p>
<p>See for yourself!</p>
<pre><code class="language-shell">k6 run k6/script.js
</code></pre>
<p>While the load test is running, I suggest watching the HPA in a separate tab.</p>
<pre><code class="language-shell">kubectl get hpa -n sample-app -w
</code></pre>
<p>As the load test progresses and the 2 starting Pods struggle to handle incoming requests, you should see both CPU and memory targets increasing, and ultimately, the <strong>replica count reaching its maximum</strong>!</p>
<pre><code class="language-shell">Deployment/sample-app   16%/50%, 10%/50%   2         8         2
Deployment/sample-app   16%/50%, 15%/50%   2         8         2
Deployment/sample-app   17%/50%, 40%/50%   2         8         2
Deployment/sample-app   18%/50%, 50%/50%   2         8         2
Deployment/sample-app   19%/50%, 60%/50%   2         8         2
Deployment/sample-app   22%/50%, 75%/50%   2         8         3
Deployment/sample-app   27%/50%, 85%/50%   2         8         3
Deployment/sample-app   24%/50%, 80%/50%   2         8         4
Deployment/sample-app   27%/50%, 80%/50%   2         8         5
Deployment/sample-app   22%/50%, 72%/50%   2         8         5
Deployment/sample-app   23%/50%, 70%/50%   2         8         6
Deployment/sample-app   25%/50%, 64%/50%   2         8         7
Deployment/sample-app   24%/50%, 61%/50%   2         8         7
Deployment/sample-app   25%/50%, 61%/50%   2         8         7
Deployment/sample-app   27%/50%, 60%/50%   2         8         8
Deployment/sample-app   28%/50%, 60%/50%   2         8         8
Deployment/sample-app   27%/50%, 57%/50%   2         8         8
</code></pre>
<p>When relying on multiple targets for a single HPA, you can find out which of those have triggered the up/downscale by consulting Kubernetes events.</p>
<pre><code class="language-shell">‚ûú kubectl get events -n sample-app
...
New size: 3; reason: cpu resource utilization (percentage of request) above target
Scaled up replica set sample-app-6bcbfc8b49 to 3
New size: 4; reason: cpu resource utilization (percentage of request) above target
Scaled up replica set sample-app-6bcbfc8b49 to 4
New size: 5; reason: cpu resource utilization (percentage of request) above target
Scaled up replica set sample-app-6bcbfc8b49 to 5
New size: 6; reason: cpu resource utilization (percentage of request) above target
Scaled up replica set sample-app-6bcbfc8b49 to 6
New size: 7; reason: cpu resource utilization (percentage of request) above target
Scaled up replica set sample-app-6bcbfc8b49 to 7
New size: 8; reason: cpu resource utilization (percentage of request) above target
Scaled up replica set sample-app-6bcbfc8b49 to 8
...
</code></pre>
<p>Now, let&rsquo;s quickly have a look at the Load Test summary and the result of the <code>http_req_duration</code> metric in particular!</p>
<pre><code class="language-shell">          /\      |‚Äæ‚Äæ| /‚Äæ‚Äæ/   /‚Äæ‚Äæ/
     /\  /  \     |  |/  /   /  /
    /  \/    \    |     (   /   ‚Äæ‚Äæ\
   /          \   |  |\  \ |  (‚Äæ)  |
  / __________ \  |__| \__\ \_____/ .io

  execution: local
     script: k6/script.js
     output: -

  scenarios: (100.00%) 1 scenario, 100 max VUs, 5m30s max duration (incl. graceful stop):
           * load: Up to 100.00 iterations/s for 5m0s over 2 stages (maxVUs: 100, gracefulStop: 30s)


     ‚úì status code is 200
     ‚úì node is kind-control-plane
     ‚úì namespace is sample-app
     ‚úì pod is sample-app-*

   ‚úì checks.........................: 100.00% ‚úì 60360    ‚úó 0
     data_received..................: 3.5 MB  12 kB/s
     data_sent......................: 1.7 MB  5.8 kB/s
     http_req_blocked...............: avg=17.57¬µs  min=1¬µs      med=9¬µs    max=5.48ms  p(90)=17¬µs    p(95)=21¬µs
     http_req_connecting............: avg=4.36¬µs   min=0s       med=0s     max=5.26ms  p(90)=0s      p(95)=0s
   ‚úì http_req_duration..............: avg=17.63ms  min=496¬µs    med=3.16ms max=1.76s   p(90)=11.38ms p(95)=51.18ms
       { expected_response:true }...: avg=17.63ms  min=496¬µs    med=3.16ms max=1.76s   p(90)=11.38ms p(95)=51.18ms
     http_req_failed................: 0.00%   ‚úì 0        ‚úó 15090
     http_req_receiving.............: avg=107.72¬µs min=10¬µs     med=78¬µs   max=7.62ms  p(90)=164¬µs   p(95)=214¬µs
     http_req_sending...............: avg=53.87¬µs  min=5¬µs      med=35¬µs   max=15.33ms p(90)=73¬µs    p(95)=95¬µs
     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s     max=0s      p(90)=0s      p(95)=0s
     http_req_waiting...............: avg=17.47ms  min=423¬µs    med=2.99ms max=1.76s   p(90)=11.08ms p(95)=51.02ms
     http_reqs......................: 15090   50.29863/s
     iteration_duration.............: avg=18.11ms  min=626.66¬µs med=3.64ms max=1.76s   p(90)=12.03ms p(95)=51.78ms
     iterations.....................: 15090   50.29863/s
     vus............................: 0       min=0      max=18
     vus_max........................: 100     min=100    max=100


running (5m00.0s), 000/100 VUs, 15090 complete and 0 interrupted iterations
load ‚úì [======================================] 000/100 VUs  5m0s  000.65 iters/s
</code></pre>
<p>As you can observe, our Golang service has performed very well under heavy load, with a Success Share of 100%, a median latency of ~3ms, and a 95th percentile latency of ~50ms!</p>
<p>We have the HPA to thank for that, as it scaled the Deployment from 2 to 8 Pods swiftly and automatically, based on the Pods resource usage!</p>
<p>We definitely would not have had the same results without an HPA‚Ä¶ Actually, why don&rsquo;t you try it yourself? üòâ</p>
<p>Just delete the HPA (<code>kubectl delete hpa sample-app -n sample-app</code>), run the load test again (<code>k6 run k6/script.js</code>) and see what happens! (spoiler alert: it&rsquo;s not pretty üò¨)</p>
<p>Once you are done, don&rsquo;t forget to uninstall the Helm release! (we won&rsquo;t be needing this one anymore)</p>
<pre><code class="language-shell">helm uninstall sample-app -n sample-app
</code></pre>
<h2 id="autoscaling-jvm-services-based-on-cpu-usage">Autoscaling JVM Services based on CPU Usage</h2>
<hr>
<p>While native services run as executable binaries, JVM services need an extra environment layer in order to run on various OSs and CPU architectures: the Java Virtual Machine (JVM).</p>
<p>This creates an issue for Pod Autoscaling, as the JVM pre-allocates more memory than it actually needs from the Pod&rsquo;s resources, for its Garbage Collector (GC). This makes memory altogether an unreliable metric to use for autoscaling a JVM-based service in Kubernetes via Metrics Server.</p>
<p>Thus, in the case of Java or other JVM-based  services, when utilizing Metrics Server for HPA, one can only rely on the CPU metric for autoscaling.</p>
<p>Let&rsquo;s experience it with a Kotlin/JVM service!</p>
<pre><code class="language-shell">helm install kotlin-sample-app/helm-chart --name-template sample-app --create-namespace -n sample-app --wait
</code></pre>
<p>If everything goes fine, you should eventually see one Deployment with the READY state.</p>
<pre><code class="language-shell">‚ûú kubectl get deploy -n sample-app
NAME         READY   UP-TO-DATE   AVAILABLE   AGE
sample-app   2/2     2            2           52s
</code></pre>
<p>Let&rsquo;s see what the resource usage for those Pods running a JVM currently is!</p>
<pre><code class="language-shell">‚ûú kubectl top pods -n sample-app
NAME                         CPU(cores)   MEMORY(bytes)
sample-app-8df8cfcd4-lg9s8   7m           105Mi
sample-app-8df8cfcd4-r9fjh   7m           105Mi
</code></pre>
<p>Interesting! As you can see, while being idle, both pods consume ~100Mi (~104Mb) of memory, which is almost 50% of the Pods memory limit! üò±<br>
As previously stated, this is due to the JVM pre-allocating memory for its Garbage Collector (GC).</p>
<p>Alright, now let&rsquo;s have a look at the HPA!</p>
<pre><code class="language-shell">‚ûú kubectl describe hpa -n sample-app
...
Metrics: ( current / target )
  resource cpu on pods (as a percentage of request):  10% / 50%
Min replicas:                                         2
Max replicas:                                         8
...
</code></pre>
<p>As announced, this time the HPA only relies on one resource metric: the CPU.</p>
<p>Alright, let&rsquo;s give our favorite Load Testing tool another go! üöÄ</p>
<pre><code class="language-shell">k6 run k6/script.js
</code></pre>
<p>As previously mentioned, I suggest watching the HPA in a separate tab.</p>
<pre><code class="language-shell">kubectl get hpa -n sample-app -w
</code></pre>
<p>As the load test progresses and the 2 starting Pods struggle to handle incoming requests, you should see the CPU target increasing, and ultimately, the <strong>replica count reaching its maximum</strong>!</p>
<pre><code class="language-shell">Deployment/sample-app   10%/50%   2         8         2
Deployment/sample-app   15%/50%   2         8         2
Deployment/sample-app   36%/50%   2         8         2
Deployment/sample-app   64%/50%   2         8         2
Deployment/sample-app   37%/50%   2         8         3
Deployment/sample-app   41%/50%   2         8         3
Deployment/sample-app   51%/50%   2         8         3
Deployment/sample-app   99%/50%   2         8         3
Deployment/sample-app   56%/50%   2         8         6
Deployment/sample-app   50%/50%   2         8         6
Deployment/sample-app   76%/50%   2         8         6
Deployment/sample-app   74%/50%   2         8         8
Deployment/sample-app   61%/50%   2         8         8
Deployment/sample-app   58%/50%   2         8         8
</code></pre>
<p>Now, let&rsquo;s quickly have a look at the Load Test summary and the result of the <code>http_req_duration</code> metric in particular!</p>
<pre><code class="language-shell">          /\      |‚Äæ‚Äæ| /‚Äæ‚Äæ/   /‚Äæ‚Äæ/
     /\  /  \     |  |/  /   /  /
    /  \/    \    |     (   /   ‚Äæ‚Äæ\
   /          \   |  |\  \ |  (‚Äæ)  |
  / __________ \  |__| \__\ \_____/ .io

  execution: local
     script: k6/script.js
     output: -

  scenarios: (100.00%) 1 scenario, 100 max VUs, 5m30s max duration (incl. graceful stop):
           * load: Up to 100.00 iterations/s for 5m0s over 2 stages (maxVUs: 100, gracefulStop: 30s)


     ‚úì status code is 200
     ‚úì node is kind-control-plane
     ‚úì namespace is sample-app
     ‚úì pod is sample-app-*

   ‚úì checks.........................: 100.00% ‚úì 60360     ‚úó 0
     data_received..................: 3.3 MB  11 kB/s
     data_sent......................: 1.7 MB  5.8 kB/s
     http_req_blocked...............: avg=18.56¬µs  min=1¬µs    med=9¬µs    max=2.37ms p(90)=17¬µs    p(95)=20¬µs
     http_req_connecting............: avg=5.52¬µs   min=0s     med=0s     max=1.65ms p(90)=0s      p(95)=0s
   ‚úì http_req_duration..............: avg=13.4ms   min=864¬µs  med=3.7ms  max=1.96s  p(90)=11.43ms p(95)=43.16ms
       { expected_response:true }...: avg=13.4ms   min=864¬µs  med=3.7ms  max=1.96s  p(90)=11.43ms p(95)=43.16ms
     http_req_failed................: 0.00%   ‚úì 0         ‚úó 15090
     http_req_receiving.............: avg=101.68¬µs min=10¬µs   med=79¬µs   max=5.31ms p(90)=167¬µs   p(95)=217¬µs
     http_req_sending...............: avg=47.68¬µs  min=4¬µs    med=37¬µs   max=5.87ms p(90)=70¬µs    p(95)=88¬µs
     http_req_tls_handshaking.......: avg=0s       min=0s     med=0s     max=0s     p(90)=0s      p(95)=0s
     http_req_waiting...............: avg=13.25ms  min=803¬µs  med=3.54ms max=1.96s  p(90)=11.25ms p(95)=43.05ms
     http_reqs......................: 15090   50.306331/s
     iteration_duration.............: avg=13.84ms  min=1.06ms med=4.17ms max=1.96s  p(90)=12.02ms p(95)=43.55ms
     iterations.....................: 15090   50.306331/s
     vus............................: 0       min=0       max=13
     vus_max........................: 100     min=100     max=100


running (5m00.0s), 000/100 VUs, 15090 complete and 0 interrupted iterations
load ‚úì [======================================] 000/100 VUs  5m0s  000.65 iters/s
</code></pre>
<p>As you can observe, our Kotlin/JVM service has performed very well under heavy load, with a Success Share of 100%, a median latency of ~3ms, and a 95th percentile latency of ~50ms!</p>
<p>Once again, the HPA was able to scale the Deployment from 2 to 8 Pods swiftly and automatically, based on the Pods CPU usage alone!</p>
<blockquote>
<p><em>Note: if you keep the Deployment idle for a few minutes, you should see the HPA gradually scaling back down to 2 Pods, due to low CPU usage.</em></p></blockquote>
<h2 id="wrapping-up">Wrapping up</h2>
<hr>
<p>That&rsquo;s it! You can now stop and delete your Kind cluster.</p>
<pre><code class="language-shell">kind delete cluster
</code></pre>
<p>To summarize, using Metrics Server we were able to:</p>
<ul>
<li>Autoscale horizontally our native service written in Golang, based on both CPU and memory usage;</li>
<li>Autoscale horizontally our JVM service written in Kotlin/JVM, based on CPU usage.</li>
</ul>
<p>Was it worth it? Did that help you understand how to implement Horizontal Pod Autoscaler in Kubernetes using Metrics Server?</p>
<p>If so, follow me on <a href="https://x.com/jhandguy">X</a>, I‚Äôll be happy to answer any of your questions and you‚Äôll be the first one to know when a new article comes out! üëå</p>
<p>See you next month, for Part 2 of my series <strong>Horizontal Pod Autoscaler in Kubernetes</strong>!</p>
<p>Bye-bye! üëã</p>

        </div>
    </div>
</section>

</body>
<footer>
    <div class="footer pt-3 has-background-black-bis">
        <div class="container pb-6 has-text-centered is-mobile columns">
            <div class="column is-narrow paddingless">
                
                
                <a class="button is-large" href="https://jhandguy.github.io/posts/incremental-mobile-force-update/"><strong>üëà</strong></a>
                
                
            </div>
            <div class="column"></div>
            <div class="column is-narrow paddingless">
                <a class="button is-large" href="#"><strong>üëÜ</strong></a>
            </div>
            <div class="column"></div>
            <div class="column is-narrow paddingless">
                
                
                <a class="button is-large" href="https://jhandguy.github.io/posts/advanced-horizontal-autoscaling/"><strong>üëâ</strong></a>
                
                
            </div>
        </div>
        <div class="content has-text-centered">
            <p class="subtitle is-6">Powered by <a href="https://gohugo.io/">Hugo</a></p>
            <a href="https://bulma.io">
                <img src="/images/footer/made-with-bulma.png" alt="Made with Bulma" width="128" height="24">
            </a>
        </div>
    </div>
</footer>

</html>
