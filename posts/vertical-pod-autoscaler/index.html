<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Vertical Pod Autoscaler in Kubernetes</title>
    <link rel="stylesheet" href="/css/bulma.min.css">
    <link rel="stylesheet" href="/css/custom.css">
    <link rel="stylesheet" href="/css/hugo.css">
</head>

<body>
<nav class="navbar">
    <div class="navbar-brand">
        <a class="navbar-item" href="/">
            Home
        </a>

        <div class="navbar-item">
            <a class="button is-link" href="/about">
                <strong>About me</strong>
            </a>
        </div>
    </div>
</nav>

<section class="section">
    <div class="container is-max-desktop">
        <div class="content">
            <p class="title is-spaced">Vertical Pod Autoscaler in Kubernetes</p>
            
            
            <div class="box">
                <p class="subtitle">Table of Contents</p>
                <nav id="TableOfContents">
  <ul>
    <li><a href="#requirements">Requirements</a></li>
    <li><a href="#creating-kind-cluster">Creating Kind Cluster</a></li>
    <li><a href="#installing-cert-manager">Installing cert-manager</a></li>
    <li><a href="#installing-nginx-ingress-controller">Installing NGINX Ingress Controller</a></li>
    <li><a href="#installing-metrics-server">Installing Metrics Server</a></li>
    <li><a href="#installing-vertical-pod-autoscaler">Installing Vertical Pod Autoscaler</a></li>
    <li><a href="#configuring-vertical-pod-autoscaler">Configuring Vertical Pod Autoscaler</a></li>
    <li><a href="#configuring-pod-disruption-budget">Configuring Pod Disruption Budget</a></li>
    <li><a href="#wrapping-up">Wrapping up</a></li>
  </ul>
</nav>
            </div>
            
            
        </div>
    </div>
    <div class="container is-max-desktop mt-6">
        <div class="content has-text-justified-tablet">
            <p>In Kubernetes, we usually think about the Horizontal Pod Autoscaler (HPA) when referring to autoscaling. In most cases, it will be the preferred way of scaling services, based on CPU usage, memory usage, or custom metrics.</p>
<blockquote>
<p><em>If you haven&rsquo;t already, go read <a href="/posts/simple-horizontal-autoscaling/">Horizontal Pod Autoscaler in Kubernetes (Part 1) - Simple Autoscaling using Metrics Server</a> and learn how to implement a Horizontal Pod Autoscaler using Metrics Server!</em></p>
</blockquote>
<p>However, while HPA can scale up and down replicas based on the current load, it is not capable of optimizing resource usage over the long term:  This is where the Vertical Pod Autoscaler (VPA) comes in.</p>
<blockquote>
<p>The VPA can be leveraged to optimize resource usage over time, based on mid to long-term observation.</p>
</blockquote>
<p>Please note that to avoid a race condition, the VPA should only be used together with HPAs that are based on custom metrics. In addition, the VPA should not be used with JVM-based services due to limited visibility into the actual memory usage of the workload (learn more about its limitations <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/verticalpodautoscaler#limitations">here</a>).</p>
<blockquote>
<p><em>If you haven&rsquo;t already, go read <a href="/posts/advanced-horizontal-autoscaling/">Horizontal Pod Autoscaler in Kubernetes (Part 2) - Advanced Autoscaling using Prometheus Adapter</a> and learn how to implement a Horizontal Pod Autoscaler using Prometheus Adapter!</em></p>
</blockquote>
<p>ğŸ¬ Hi there, I&rsquo;m Jean!</p>
<p>In this article, we&rsquo;re going to learn how to use Vertical Pod Autoscaler (VPA) to vertically scale services in Kubernetes automatically based on resource metrics! ğŸ’ª</p>
<h2 id="requirements">Requirements</h2>
<hr>
<p>Before we start, make sure you have the following tools installed:</p>
<ul>
<li><a href="https://kind.sigs.k8s.io/docs/user/quick-start/#installation">Kind</a></li>
<li><a href="https://kubernetes.io/docs/tasks/tools/">Kubectl</a></li>
<li><a href="https://helm.sh/docs/intro/install/">Helm</a></li>
<li><a href="https://k6.io/docs/getting-started/installation/">K6</a></li>
</ul>
<blockquote>
<p><em>Note: for MacOS users or Linux users using Homebrew, simply run:</em><br>
<code>brew install kind kubectl helm k6</code></p>
</blockquote>
<p>All set? Letâ€™s go! ğŸ</p>
<h2 id="creating-kind-cluster">Creating Kind Cluster</h2>
<hr>
<p><a href="https://kind.sigs.k8s.io/">Kind</a> is a tool for running local Kubernetes clusters using Docker container â€œnodesâ€.
It was primarily designed for testing Kubernetes itself, but may be used for local development or CI.</p>
<p>I donâ€™t expect you to have a demo project in handy, so <a href="https://github.com/jhandguy/canary-deployment">I built one</a> for you.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">git clone https://github.com/jhandguy/vertical-pod-autoscaler.git
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> vertical-pod-autoscaler
</span></span></code></pre></div><p>Alright, let&rsquo;s spin up our Kind cluster! ğŸš€</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kind create cluster --image kindest/node:v1.27.3 --config<span class="o">=</span>kind/cluster.yaml
</span></span><span class="line"><span class="cl">Creating cluster <span class="s2">&#34;kind&#34;</span> ...
</span></span><span class="line"><span class="cl"> âœ“ Ensuring node image <span class="o">(</span>kindest/node:v1.27.3<span class="o">)</span> ğŸ–¼
</span></span><span class="line"><span class="cl"> âœ“ Preparing nodes ğŸ“¦
</span></span><span class="line"><span class="cl"> âœ“ Writing configuration ğŸ“œ
</span></span><span class="line"><span class="cl"> âœ“ Starting control-plane ğŸ•¹ï¸
</span></span><span class="line"><span class="cl"> âœ“ Installing CNI ğŸ”Œ
</span></span><span class="line"><span class="cl"> âœ“ Installing StorageClass ğŸ’¾
</span></span><span class="line"><span class="cl">Set kubectl context to <span class="s2">&#34;kind-kind&#34;</span>
</span></span><span class="line"><span class="cl">You can now use your cluster with:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl cluster-info --context kind-kind
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community ğŸ™‚
</span></span></code></pre></div><h2 id="installing-cert-manager">Installing cert-manager</h2>
<p><a href="https://github.com/cert-manager/cert-manager">cert-manager</a> is a Kubernetes addon that automates the management and issuance of TLS certificates from various issuing sources. It ensures certificates are valid and up to date periodically, and attempts to renew certificates at an appropriate time before expiry.</p>
<p>cert-manager can be installed via its <a href="https://github.com/cert-manager/cert-manager/tree/master/deploy/charts/cert-manager">Helm chart</a>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">helm repo add jetstack https://charts.jetstack.io
</span></span><span class="line"><span class="cl">helm install jetstack/cert-manager --name-template cert-manager --create-namespace -n cert-manager --values kind/cert-manager-values.yaml --version 1.13.2 --wait
</span></span></code></pre></div><p>If everything went fine, you should be able to see three newly spawned Deployments with the READY state!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get deploy -n cert-manager
</span></span><span class="line"><span class="cl">NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span class="line"><span class="cl">cert-manager              1/1     <span class="m">1</span>            <span class="m">1</span>           6m27m
</span></span><span class="line"><span class="cl">cert-manager-cainjector   1/1     <span class="m">1</span>            <span class="m">1</span>           6m27m
</span></span><span class="line"><span class="cl">cert-manager-webhook      1/1     <span class="m">1</span>            <span class="m">1</span>           6m27m
</span></span></code></pre></div><h2 id="installing-nginx-ingress-controller">Installing NGINX Ingress Controller</h2>
<hr>
<p><a href="https://github.com/kubernetes/ingress-nginx">NGINX Ingress Controller</a> is one of the <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/#additional-controllers">many available Kubernetes Ingress Controllers</a>, which acts as a load balancer and satisfies routing rules specified in <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/#what-is-ingress">Ingress</a> resources, using the <a href="https://nginx.org/en/">NGINX reverse proxy</a>.</p>
<p>NGINX Ingress Controller can be installed via its <a href="https://github.com/kubernetes/ingress-nginx/tree/main/charts/ingress-nginx">Helm chart</a>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
</span></span><span class="line"><span class="cl">helm install ingress-nginx/ingress-nginx --name-template ingress-nginx --create-namespace -n ingress-nginx --values kind/ingress-nginx-values.yaml --version 4.8.3 --wait
</span></span></code></pre></div><p>Now, if everything goes according to plan, you should be able to see the <strong>ingress-nginx-controller</strong> Deployment running.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get deploy -n ingress-nginx
</span></span><span class="line"><span class="cl">NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span class="line"><span class="cl">ingress-nginx-controller   1/1     <span class="m">1</span>            <span class="m">1</span>           4m35s
</span></span></code></pre></div><h2 id="installing-metrics-server">Installing Metrics Server</h2>
<hr>
<p><a href="https://github.com/kubernetes-sigs/metrics-server">Metrics Server</a> is a source of container resource metrics, which collects them from Kubelets and exposes them in Kubernetes API server through <a href="https://github.com/kubernetes/metrics">Metrics API</a> for use by <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler</a> and <a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/">Vertical Pod Autoscaler</a>.</p>
<p>Metrics Server can be installed via its <a href="https://github.com/kubernetes-sigs/metrics-server/tree/master/charts/metrics-server">Helm chart</a>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server
</span></span><span class="line"><span class="cl">helm install metrics-server/metrics-server --name-template metrics-server --create-namespace -n metrics-server --values kind/metrics-server-values.yaml --version 3.11.0 --wait
</span></span></code></pre></div><p>Now, if everything goes according to plan, you should be able to see the <strong>metrics-server</strong> Deployment running.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get deploy -n metrics-server
</span></span><span class="line"><span class="cl">NAME             READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span class="line"><span class="cl">metrics-server   1/1     <span class="m">1</span>            <span class="m">1</span>           38s
</span></span></code></pre></div><h2 id="installing-vertical-pod-autoscaler">Installing Vertical Pod Autoscaler</h2>
<hr>
<p><a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler">Vertical Pod Autoscaler</a> (VPA) is a component of the <a href="https://github.com/kubernetes/autoscaler">Kubernetes Autoscaler</a> that frees users from the necessity of setting up-to-date resource limits and requests for the containers in their pods.</p>
<p>When configured, it will set the requests automatically based on usage and thus allow proper scheduling onto nodes so that the appropriate resource amount is available for each pod.
It will also maintain ratios between limits and requests that were specified in the initial container configuration.</p>
<p>It can both down-scale pods that are over-requesting resources, and also up-scale pods that are under-requesting resources based on their usage over time.</p>
<blockquote>
<p><em>Note: VPA is still in its beta phase, using it for production is at your own risk.</em></p>
</blockquote>
<p>As of this writing, Kubernetes  does not provide an official Helm chart, so I went ahead and built one!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">helm install helm-chart --name-template vertical-pod-autoscaler --create-namespace -n vertical-pod-autoscaler --wait
</span></span></code></pre></div><p>If everything goes fine, you should eventually see three Deployments with the READY state!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get deploy -n vertical-pod-autoscaler
</span></span><span class="line"><span class="cl">NAME                               READY UP-TO-DATE AVAILABLE AGE
</span></span><span class="line"><span class="cl">vert...scaler-admission-controller 1/1   <span class="m">1</span>          <span class="m">1</span>         2m32s
</span></span><span class="line"><span class="cl">vert...scaler-recommender          1/1   <span class="m">1</span>          <span class="m">1</span>         2m32s
</span></span><span class="line"><span class="cl">vert...scaler-updater              1/1   <span class="m">1</span>          <span class="m">1</span>         2m32s
</span></span></code></pre></div><p>As you can observe, the VPA is split into 3 separate components:</p>
<ul>
<li>The <a href="https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/pkg/recommender">Recommender</a> computes the recommended resource requests for pods based on historical and current usage of the resources. The current recommendations are then put in the status of the VPA resource, where they can be inspected;</li>
<li>The <a href="https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/pkg/updater">Updater</a> decides which pods should be restarted based on resource allocation recommendations calculated by Recommender. If a pod should be updated, Updater will try to evict the pod. It respects the pod disruption budget, by using the Eviction API to evict pods. Updater does not perform the actual resources update but relies on Admission Controller to update pod resources when the pod is recreated after eviction.</li>
<li>The <a href="https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/pkg/admission-controller">Admission Controller</a> will get a request from the API server for each pod creation and will either decide there&rsquo;s no matching VPA configuration or find the corresponding one and use the current recommendation to set resource requests in the pod.</li>
</ul>
<h2 id="configuring-vertical-pod-autoscaler">Configuring Vertical Pod Autoscaler</h2>
<hr>
<p>Now that the Vertical Pod Autoscaler is up and running, let&rsquo;s get to it, shall we? ğŸ§</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">helm install sample-app/helm-chart --name-template sample-app --create-namespace -n sample-app --wait
</span></span></code></pre></div><p>If everything goes fine, you should eventually see one Deployment with the READY state.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get deploy -n sample-app
</span></span><span class="line"><span class="cl">NAME         READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span class="line"><span class="cl">sample-app   3/3     <span class="m">3</span>            <span class="m">3</span>           58s
</span></span></code></pre></div><p>Alright, now let&rsquo;s have a look at the VPA!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl describe vpa -n sample-app
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">Spec:
</span></span><span class="line"><span class="cl">  Resource Policy:
</span></span><span class="line"><span class="cl">    Container Policies:
</span></span><span class="line"><span class="cl">      Container Name:  sample-app
</span></span><span class="line"><span class="cl">      Controlled Resources:
</span></span><span class="line"><span class="cl">        cpu
</span></span><span class="line"><span class="cl">        memory
</span></span><span class="line"><span class="cl">      Max Allowed:
</span></span><span class="line"><span class="cl">        Cpu:     100m
</span></span><span class="line"><span class="cl">        Memory:  200Mi
</span></span><span class="line"><span class="cl">      Min Allowed:
</span></span><span class="line"><span class="cl">        Cpu:     10m
</span></span><span class="line"><span class="cl">        Memory:  20Mi
</span></span><span class="line"><span class="cl">  Target Ref:
</span></span><span class="line"><span class="cl">    API Version:  apps/v1
</span></span><span class="line"><span class="cl">    Kind:         Deployment
</span></span><span class="line"><span class="cl">    Name:         sample-app
</span></span><span class="line"><span class="cl">  Update Policy:
</span></span><span class="line"><span class="cl">    Update Mode:  Auto
</span></span></code></pre></div><p>As you can see, this VPA is configured to scale the service based on its CPU and memory resources.
Its <strong>spec</strong> states that the minimum allowed CPU/memory is <em>10m/20Mi</em> and the maximum is <em>100m/200Mi</em>.</p>
<p>Finally, its <strong>update policy</strong> is in &ldquo;Auto&rdquo; mode, meaning that VPA assigns resource requests on pod creation as well as updates them on existing pods using the preferred update mechanism.</p>
<p>Currently, both the resource requests and limits are matching the VPA&rsquo;s minimum allowance.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get pods -n sample-app -o yaml <span class="p">|</span> grep -A <span class="m">6</span> <span class="s1">&#39;resources:&#39;</span>
</span></span><span class="line"><span class="cl">      resources:
</span></span><span class="line"><span class="cl">        limits:
</span></span><span class="line"><span class="cl">          cpu: 10m
</span></span><span class="line"><span class="cl">          memory: 20Mi
</span></span><span class="line"><span class="cl">        requests:
</span></span><span class="line"><span class="cl">          cpu: 10m
</span></span><span class="line"><span class="cl">          memory: 20Mi
</span></span><span class="line"><span class="cl">--
</span></span><span class="line"><span class="cl">      resources:
</span></span><span class="line"><span class="cl">        limits:
</span></span><span class="line"><span class="cl">          cpu: 10m
</span></span><span class="line"><span class="cl">          memory: 20Mi
</span></span><span class="line"><span class="cl">        requests:
</span></span><span class="line"><span class="cl">          cpu: 10m
</span></span><span class="line"><span class="cl">          memory: 20Mi
</span></span><span class="line"><span class="cl">--
</span></span><span class="line"><span class="cl">      resources:
</span></span><span class="line"><span class="cl">        limits:
</span></span><span class="line"><span class="cl">          cpu: 10m
</span></span><span class="line"><span class="cl">          memory: 20Mi
</span></span><span class="line"><span class="cl">        requests:
</span></span><span class="line"><span class="cl">          cpu: 10m
</span></span><span class="line"><span class="cl">          memory: 20Mi
</span></span></code></pre></div><p>Now, let&rsquo;s give some load to our service and see what happens!</p>
<p>For Load Testing, I really recommend <a href="https://k6.io/docs/">k6</a> from the Grafana Labs team. It is a dead-simple yet super powerful tool with very extensive documentation.</p>
<p>See for yourself!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">k6 run k6/script.js
</span></span></code></pre></div><p>While k6 is gradually increasing strain on the pods&rsquo; CPU usage, let&rsquo;s watch out for any <code>EvictedByVPA</code> events in a second tab: eventually, you should see all 3 pods get evicted simultaneously!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get events -n sample-app -w <span class="p">|</span> grep EvictedByVPA
</span></span><span class="line"><span class="cl">... Pod was evicted by VPA Updater to apply resource recommendation.
</span></span><span class="line"><span class="cl">... Pod was evicted by VPA Updater to apply resource recommendation.
</span></span><span class="line"><span class="cl">... Pod was evicted by VPA Updater to apply resource recommendation.
</span></span></code></pre></div><p>As soon as this happens, have a look at the updated pods&rsquo; resource requests and limits: the CPU/memory requests/limits should have doubled in value (CPU from 10m to 20m and memory from 10Mi to 20Mi).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get pods -n sample-app -o yaml <span class="p">|</span> grep -A <span class="m">6</span> <span class="s1">&#39;resources:&#39;</span>
</span></span><span class="line"><span class="cl">      resources:
</span></span><span class="line"><span class="cl">        limits:
</span></span><span class="line"><span class="cl">          cpu: 20m
</span></span><span class="line"><span class="cl">          memory: <span class="s2">&#34;20971520&#34;</span>
</span></span><span class="line"><span class="cl">        requests:
</span></span><span class="line"><span class="cl">          cpu: 20m
</span></span><span class="line"><span class="cl">          memory: <span class="s2">&#34;20971520&#34;</span>
</span></span><span class="line"><span class="cl">--
</span></span><span class="line"><span class="cl">      resources:
</span></span><span class="line"><span class="cl">        limits:
</span></span><span class="line"><span class="cl">          cpu: 20m
</span></span><span class="line"><span class="cl">          memory: <span class="s2">&#34;20971520&#34;</span>
</span></span><span class="line"><span class="cl">        requests:
</span></span><span class="line"><span class="cl">          cpu: 20m
</span></span><span class="line"><span class="cl">          memory: <span class="s2">&#34;20971520&#34;</span>
</span></span><span class="line"><span class="cl">--
</span></span><span class="line"><span class="cl">      resources:
</span></span><span class="line"><span class="cl">        limits:
</span></span><span class="line"><span class="cl">          cpu: 20m
</span></span><span class="line"><span class="cl">          memory: <span class="s2">&#34;20971520&#34;</span>
</span></span><span class="line"><span class="cl">        requests:
</span></span><span class="line"><span class="cl">          cpu: 20m
</span></span><span class="line"><span class="cl">          memory: <span class="s2">&#34;20971520&#34;</span>
</span></span></code></pre></div><p>This means Vertical Pod Autoscaler successfully evicted the pods in order to increase their resource requests and limits! ğŸ‰</p>
<p>Once k6 is done, have a look at the Load Test summary and the result of the <code>status code</code> counter metric in particular.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">          /<span class="se">\ </span>     <span class="p">|</span>â€¾â€¾<span class="p">|</span> /â€¾â€¾/   /â€¾â€¾/
</span></span><span class="line"><span class="cl">     /<span class="se">\ </span> /  <span class="se">\ </span>    <span class="p">|</span>  <span class="p">|</span>/  /   /  /
</span></span><span class="line"><span class="cl">    /  <span class="se">\/</span>    <span class="se">\ </span>   <span class="p">|</span>     <span class="o">(</span>   /   â€¾â€¾<span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   /          <span class="se">\ </span>  <span class="p">|</span>  <span class="p">|</span><span class="se">\ </span> <span class="se">\ </span><span class="p">|</span>  <span class="o">(</span>â€¾<span class="o">)</span>  <span class="p">|</span>
</span></span><span class="line"><span class="cl">  / __________ <span class="se">\ </span> <span class="p">|</span>__<span class="p">|</span> <span class="se">\_</span>_<span class="se">\ \_</span>____/ .io
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  execution: <span class="nb">local</span>
</span></span><span class="line"><span class="cl">     script: k6/script.js
</span></span><span class="line"><span class="cl">     output: -
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  scenarios: <span class="o">(</span>100.00%<span class="o">)</span> <span class="m">1</span> scenario, <span class="m">200</span> max VUs, 10m30s max duration <span class="o">(</span>incl. graceful stop<span class="o">)</span>:
</span></span><span class="line"><span class="cl">           * load: Up to 40.00 iterations/s <span class="k">for</span> 10m0s over <span class="m">3</span> stages <span class="o">(</span>maxVUs: 200, gracefulStop: 30s<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     âœ— status code is <span class="m">200</span>
</span></span><span class="line"><span class="cl">      â†³  97% â€” âœ“ <span class="m">17724</span> / âœ— <span class="m">365</span>
</span></span><span class="line"><span class="cl">     âœ— node is kind-control-plane
</span></span><span class="line"><span class="cl">      â†³  97% â€” âœ“ <span class="m">17724</span> / âœ— <span class="m">365</span>
</span></span><span class="line"><span class="cl">     âœ— namespace is sample-app
</span></span><span class="line"><span class="cl">      â†³  97% â€” âœ“ <span class="m">17724</span> / âœ— <span class="m">365</span>
</span></span><span class="line"><span class="cl">     âœ— pod is sample-app-*
</span></span><span class="line"><span class="cl">      â†³  97% â€” âœ“ <span class="m">17724</span> / âœ— <span class="m">365</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   âœ“ checks.........................: 97.98% âœ“ <span class="m">70896</span>     âœ— <span class="m">1460</span>
</span></span><span class="line"><span class="cl">     data_received..................: 4.2 MB 7.1 kB/s
</span></span><span class="line"><span class="cl">     data_sent......................: 2.1 MB 3.5 kB/s
</span></span><span class="line"><span class="cl">     http_req_blocked...............: <span class="nv">avg</span><span class="o">=</span>18.39Âµs  <span class="nv">min</span><span class="o">=</span>2Âµs   <span class="nv">med</span><span class="o">=</span>8Âµs    <span class="nv">max</span><span class="o">=</span>2.93ms  p<span class="o">(</span>90<span class="o">)=</span>17Âµs     p<span class="o">(</span>95<span class="o">)=</span>20Âµs
</span></span><span class="line"><span class="cl">     http_req_connecting............: <span class="nv">avg</span><span class="o">=</span>5.71Âµs   <span class="nv">min</span><span class="o">=</span>0s    <span class="nv">med</span><span class="o">=</span>0s     <span class="nv">max</span><span class="o">=</span>2.74ms  p<span class="o">(</span>90<span class="o">)=</span>0s       p<span class="o">(</span>95<span class="o">)=</span>0s
</span></span><span class="line"><span class="cl">   âœ“ http_req_duration..............: <span class="nv">avg</span><span class="o">=</span>188.13ms <span class="nv">min</span><span class="o">=</span>491Âµs <span class="nv">med</span><span class="o">=</span>4.57ms <span class="nv">max</span><span class="o">=</span>59.99s  p<span class="o">(</span>90<span class="o">)=</span>269.43ms p<span class="o">(</span>95<span class="o">)=</span>646.78ms
</span></span><span class="line"><span class="cl">       <span class="o">{</span> expected_response:true <span class="o">}</span>...: <span class="nv">avg</span><span class="o">=</span>129.55ms <span class="nv">min</span><span class="o">=</span>491Âµs <span class="nv">med</span><span class="o">=</span>4.62ms <span class="nv">max</span><span class="o">=</span>7.3s    p<span class="o">(</span>90<span class="o">)=</span>261.24ms p<span class="o">(</span>95<span class="o">)=</span>602.03ms
</span></span><span class="line"><span class="cl">     http_req_failed................: 2.01%  âœ“ <span class="m">365</span>       âœ— <span class="m">17724</span>
</span></span><span class="line"><span class="cl">     http_req_receiving.............: <span class="nv">avg</span><span class="o">=</span>98.96Âµs  <span class="nv">min</span><span class="o">=</span>0s    <span class="nv">med</span><span class="o">=</span>75Âµs   <span class="nv">max</span><span class="o">=</span>4.27ms  p<span class="o">(</span>90<span class="o">)=</span>159Âµs    p<span class="o">(</span>95<span class="o">)=</span>209Âµs
</span></span><span class="line"><span class="cl">     http_req_sending...............: <span class="nv">avg</span><span class="o">=</span>49.92Âµs  <span class="nv">min</span><span class="o">=</span>7Âµs   <span class="nv">med</span><span class="o">=</span>34Âµs   <span class="nv">max</span><span class="o">=</span>14.39ms p<span class="o">(</span>90<span class="o">)=</span>72Âµs     p<span class="o">(</span>95<span class="o">)=</span>93Âµs
</span></span><span class="line"><span class="cl">     http_req_tls_handshaking.......: <span class="nv">avg</span><span class="o">=</span>0s       <span class="nv">min</span><span class="o">=</span>0s    <span class="nv">med</span><span class="o">=</span>0s     <span class="nv">max</span><span class="o">=</span>0s      p<span class="o">(</span>90<span class="o">)=</span>0s       p<span class="o">(</span>95<span class="o">)=</span>0s
</span></span><span class="line"><span class="cl">     http_req_waiting...............: <span class="nv">avg</span><span class="o">=</span>187.99ms <span class="nv">min</span><span class="o">=</span>451Âµs <span class="nv">med</span><span class="o">=</span>4.38ms <span class="nv">max</span><span class="o">=</span>59.99s  p<span class="o">(</span>90<span class="o">)=</span>269.31ms p<span class="o">(</span>95<span class="o">)=</span>646.69ms
</span></span><span class="line"><span class="cl">     http_reqs......................: <span class="m">18089</span>  30.147771/s
</span></span><span class="line"><span class="cl">     iteration_duration.............: <span class="nv">avg</span><span class="o">=</span>188.59ms <span class="nv">min</span><span class="o">=</span>666Âµs <span class="nv">med</span><span class="o">=</span>5.11ms <span class="nv">max</span><span class="o">=</span>1m0s    p<span class="o">(</span>90<span class="o">)=</span>270.13ms p<span class="o">(</span>95<span class="o">)=</span>647.49ms
</span></span><span class="line"><span class="cl">     iterations.....................: <span class="m">18089</span>  30.147771/s
</span></span><span class="line"><span class="cl">     vus............................: <span class="m">0</span>      <span class="nv">min</span><span class="o">=</span><span class="m">0</span>       <span class="nv">max</span><span class="o">=</span><span class="m">145</span>
</span></span><span class="line"><span class="cl">     vus_max........................: <span class="m">200</span>    <span class="nv">min</span><span class="o">=</span><span class="m">200</span>     <span class="nv">max</span><span class="o">=</span><span class="m">200</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">running <span class="o">(</span>10m00.0s<span class="o">)</span>, 000/200 VUs, <span class="m">18089</span> <span class="nb">complete</span> and <span class="m">0</span> interrupted iterations
</span></span><span class="line"><span class="cl">load âœ“ <span class="o">[======================================]</span> 000/200 VUs  10m0s  00.41 iters/s
</span></span></code></pre></div><p>Uh-ohâ€¦ It looks like we had some downtime! ğŸ˜±</p>
<p>Thankfully, our service was able to restart relatively fast and <strong>365</strong> out of <strong>17724</strong> requests failed. But for a service with a slower startup time, this could have led to an incident! ğŸš¨</p>
<p>This is due to the fact that vertical scaling, in essence, cannot happen without a restart: a pod&rsquo;s CPU and/or memory cannot be increased in place. Instead, the pod must be terminated and a new one created with increased resources.</p>
<p>So how do we ensure the availability of our service during vertical autoscaling then?</p>
<blockquote>
<p>This is where the Pod Disruption Budget (PDB) comes in!</p>
</blockquote>
<p>We&rsquo;ll get to that in a minute, let&rsquo;s uninstall our Helm release first! (we won&rsquo;t be needing this one anymore)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">helm uninstall sample-app -n sample-app
</span></span></code></pre></div><h2 id="configuring-pod-disruption-budget">Configuring Pod Disruption Budget</h2>
<hr>
<p>To prevent downtimes during pod disruption such as the one we previously experienced, a Pod Disruption Budget (PDB) can be configured.</p>
<p>A PDB limits the number of pods that are down simultaneously from voluntary disruptions. It can be configured to sustain either a minimum amount of available pods (<code>minAvailable</code>), or a maximum amount of unavailable pods (<code>maxUnavailable</code>).</p>
<p>Let&rsquo;s see what happens if we try to autoscale vertically the same application but with a Pod Disruption Budget with <code>maxUnavailable: 1</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">helm install sample-app/helm-chart --name-template sample-app --set podDisruptionBudget.enabled<span class="o">=</span><span class="nb">true</span> --create-namespace -n sample-app --wait
</span></span></code></pre></div><p>Once again, you should eventually see one Deployment with the READY state.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get deploy -n sample-app
</span></span><span class="line"><span class="cl">NAME         READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span class="line"><span class="cl">sample-app   3/3     <span class="m">3</span>            <span class="m">3</span>           32s
</span></span></code></pre></div><p>Alright, now let&rsquo;s have a look at the PDB!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl describe pdb -n sample-app
</span></span><span class="line"><span class="cl">Name:             sample-app
</span></span><span class="line"><span class="cl">Namespace:        sample-app
</span></span><span class="line"><span class="cl">Max unavailable:  <span class="m">1</span>
</span></span><span class="line"><span class="cl">Selector:         <span class="nv">app</span><span class="o">=</span>sample-app
</span></span><span class="line"><span class="cl">Status:
</span></span><span class="line"><span class="cl">    Allowed disruptions:  <span class="m">1</span>
</span></span><span class="line"><span class="cl">    Current:              <span class="m">3</span>
</span></span><span class="line"><span class="cl">    Desired:              <span class="m">2</span>
</span></span><span class="line"><span class="cl">    Total:                <span class="m">3</span>
</span></span></code></pre></div><p>As you can see, this PDB is configured to prevent more than 1 pod to be unavailable during a voluntary pod disruption (such as pod eviction by VPA).</p>
<p>Now, let&rsquo;s see how our service is going to behave under load with a PDB!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">k6 run k6/script.js
</span></span></code></pre></div><p>Once again, while k6 is gradually increasing strain on the pods&rsquo; CPU usage, let&rsquo;s watch out for any <code>EvictedByVPA</code> events in a second tab: eventually, you should see all 3 pods get evicted but this time, only one by one!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">âœ kubectl get events -n sample-app -w <span class="p">|</span> grep EvictedByVPA
</span></span><span class="line"><span class="cl">... Pod was evicted by VPA Updater to apply resource recommendation.
</span></span><span class="line"><span class="cl">... Pod was evicted by VPA Updater to apply resource recommendation.
</span></span><span class="line"><span class="cl">... Pod was evicted by VPA Updater to apply resource recommendation.
</span></span></code></pre></div><p>Once k6 is done, have a look at the Load Test summary and the result of the <code>status code</code> counter metric in particular.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">          /<span class="se">\ </span>     <span class="p">|</span>â€¾â€¾<span class="p">|</span> /â€¾â€¾/   /â€¾â€¾/
</span></span><span class="line"><span class="cl">     /<span class="se">\ </span> /  <span class="se">\ </span>    <span class="p">|</span>  <span class="p">|</span>/  /   /  /
</span></span><span class="line"><span class="cl">    /  <span class="se">\/</span>    <span class="se">\ </span>   <span class="p">|</span>     <span class="o">(</span>   /   â€¾â€¾<span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   /          <span class="se">\ </span>  <span class="p">|</span>  <span class="p">|</span><span class="se">\ </span> <span class="se">\ </span><span class="p">|</span>  <span class="o">(</span>â€¾<span class="o">)</span>  <span class="p">|</span>
</span></span><span class="line"><span class="cl">  / __________ <span class="se">\ </span> <span class="p">|</span>__<span class="p">|</span> <span class="se">\_</span>_<span class="se">\ \_</span>____/ .io
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  execution: <span class="nb">local</span>
</span></span><span class="line"><span class="cl">     script: k6/script.js
</span></span><span class="line"><span class="cl">     output: -
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  scenarios: <span class="o">(</span>100.00%<span class="o">)</span> <span class="m">1</span> scenario, <span class="m">200</span> max VUs, 10m30s max duration <span class="o">(</span>incl. graceful stop<span class="o">)</span>:
</span></span><span class="line"><span class="cl">           * load: Up to 40.00 iterations/s <span class="k">for</span> 10m0s over <span class="m">3</span> stages <span class="o">(</span>maxVUs: 200, gracefulStop: 30s<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     âœ“ status code is <span class="m">200</span>
</span></span><span class="line"><span class="cl">     âœ“ node is kind-control-plane
</span></span><span class="line"><span class="cl">     âœ“ namespace is sample-app
</span></span><span class="line"><span class="cl">     âœ“ pod is sample-app-*
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   âœ“ checks.........................: 100.00% âœ“ <span class="m">72356</span>     âœ— <span class="m">0</span>
</span></span><span class="line"><span class="cl">     data_received..................: 4.2 MB  7.0 kB/s
</span></span><span class="line"><span class="cl">     data_sent......................: 2.1 MB  3.5 kB/s
</span></span><span class="line"><span class="cl">     http_req_blocked...............: <span class="nv">avg</span><span class="o">=</span>19.7Âµs   <span class="nv">min</span><span class="o">=</span>2Âµs      <span class="nv">med</span><span class="o">=</span>7Âµs    <span class="nv">max</span><span class="o">=</span>2.95ms  p<span class="o">(</span>90<span class="o">)=</span>16Âµs     p<span class="o">(</span>95<span class="o">)=</span>21Âµs
</span></span><span class="line"><span class="cl">     http_req_connecting............: <span class="nv">avg</span><span class="o">=</span>6.86Âµs   <span class="nv">min</span><span class="o">=</span>0s       <span class="nv">med</span><span class="o">=</span>0s     <span class="nv">max</span><span class="o">=</span>2.24ms  p<span class="o">(</span>90<span class="o">)=</span>0s       p<span class="o">(</span>95<span class="o">)=</span>0s
</span></span><span class="line"><span class="cl">   âœ“ http_req_duration..............: <span class="nv">avg</span><span class="o">=</span>103.43ms <span class="nv">min</span><span class="o">=</span>452Âµs    <span class="nv">med</span><span class="o">=</span>6.4ms  <span class="nv">max</span><span class="o">=</span>5.29s   p<span class="o">(</span>90<span class="o">)=</span>259.88ms p<span class="o">(</span>95<span class="o">)=</span>484.22ms
</span></span><span class="line"><span class="cl">       <span class="o">{</span> expected_response:true <span class="o">}</span>...: <span class="nv">avg</span><span class="o">=</span>103.43ms <span class="nv">min</span><span class="o">=</span>452Âµs    <span class="nv">med</span><span class="o">=</span>6.4ms  <span class="nv">max</span><span class="o">=</span>5.29s   p<span class="o">(</span>90<span class="o">)=</span>259.88ms p<span class="o">(</span>95<span class="o">)=</span>484.22ms
</span></span><span class="line"><span class="cl">     http_req_failed................: 0.00%   âœ“ <span class="m">0</span>         âœ— <span class="m">18089</span>
</span></span><span class="line"><span class="cl">     http_req_receiving.............: <span class="nv">avg</span><span class="o">=</span>99.34Âµs  <span class="nv">min</span><span class="o">=</span>8Âµs      <span class="nv">med</span><span class="o">=</span>77Âµs   <span class="nv">max</span><span class="o">=</span>5.42ms  p<span class="o">(</span>90<span class="o">)=</span>166Âµs    p<span class="o">(</span>95<span class="o">)=</span>212Âµs
</span></span><span class="line"><span class="cl">     http_req_sending...............: <span class="nv">avg</span><span class="o">=</span>51.86Âµs  <span class="nv">min</span><span class="o">=</span>9Âµs      <span class="nv">med</span><span class="o">=</span>33Âµs   <span class="nv">max</span><span class="o">=</span>18.76ms p<span class="o">(</span>90<span class="o">)=</span>71Âµs     p<span class="o">(</span>95<span class="o">)=</span>96.59Âµs
</span></span><span class="line"><span class="cl">     http_req_tls_handshaking.......: <span class="nv">avg</span><span class="o">=</span>0s       <span class="nv">min</span><span class="o">=</span>0s       <span class="nv">med</span><span class="o">=</span>0s     <span class="nv">max</span><span class="o">=</span>0s      p<span class="o">(</span>90<span class="o">)=</span>0s       p<span class="o">(</span>95<span class="o">)=</span>0s
</span></span><span class="line"><span class="cl">     http_req_waiting...............: <span class="nv">avg</span><span class="o">=</span>103.28ms <span class="nv">min</span><span class="o">=</span>418Âµs    <span class="nv">med</span><span class="o">=</span>6.2ms  <span class="nv">max</span><span class="o">=</span>5.29s   p<span class="o">(</span>90<span class="o">)=</span>259.8ms  p<span class="o">(</span>95<span class="o">)=</span>483.99ms
</span></span><span class="line"><span class="cl">     http_reqs......................: <span class="m">18089</span>   30.148343/s
</span></span><span class="line"><span class="cl">     iteration_duration.............: <span class="nv">avg</span><span class="o">=</span>103.9ms  <span class="nv">min</span><span class="o">=</span>625.62Âµs <span class="nv">med</span><span class="o">=</span>6.98ms <span class="nv">max</span><span class="o">=</span>5.29s   p<span class="o">(</span>90<span class="o">)=</span>260.24ms p<span class="o">(</span>95<span class="o">)=</span>485.04ms
</span></span><span class="line"><span class="cl">     iterations.....................: <span class="m">18089</span>   30.148343/s
</span></span><span class="line"><span class="cl">     vus............................: <span class="m">0</span>       <span class="nv">min</span><span class="o">=</span><span class="m">0</span>       <span class="nv">max</span><span class="o">=</span><span class="m">69</span>
</span></span><span class="line"><span class="cl">     vus_max........................: <span class="m">200</span>     <span class="nv">min</span><span class="o">=</span><span class="m">200</span>     <span class="nv">max</span><span class="o">=</span><span class="m">200</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">running <span class="o">(</span>10m00.0s<span class="o">)</span>, 000/200 VUs, <span class="m">18089</span> <span class="nb">complete</span> and <span class="m">0</span> interrupted iterations
</span></span><span class="line"><span class="cl">load âœ“ <span class="o">[======================================]</span> 000/200 VUs  10m0s  00.41 iters/s
</span></span></code></pre></div><p>Yay! ğŸ‰<br>
This time, our service handled pod disruption beautifully and not a single request failed!</p>
<p>Thanks to the Pod Disruption Budget, a pod can only be evicted if all other pods are up, ensuring that at least 2 pods are available to handle the traffic.</p>
<p>This is what we call: <a href="https://en.wikipedia.org/wiki/High_availability">High availability</a>! ğŸš€</p>
<h2 id="wrapping-up">Wrapping up</h2>
<hr>
<p>That&rsquo;s it! You can now stop and delete your Kind cluster.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kind delete cluster
</span></span></code></pre></div><p>To summarize, using Vertical Pod Autoscaler (VPA) we were able to:</p>
<ul>
<li>Autoscale vertically our service, based on resource metrics;</li>
<li>Prevent downtime during pod eviction thanks to Pod Disruption Budget.</li>
</ul>
<p>Was it worth it? Did that help you understand how to implement Vertical Pod Autoscaler in Kubernetes?</p>
<p>If so, follow me on <a href="https://twitter.com/jhandguy">Twitter</a>, Iâ€™ll be happy to answer any of your questions and youâ€™ll be the first one to know when a new article comes out! ğŸ‘Œ</p>
<p>Bye-bye! ğŸ‘‹</p>

        </div>
    </div>
</section>

</body>
<footer>
    <div class="footer pt-3 has-background-black-bis">
        <div class="container pb-6 has-text-centered is-mobile columns">
            <div class="column is-narrow paddingless">
                
                
                <a class="button is-large" href="https://jhandguy.github.io/posts/advanced-horizontal-autoscaling/"><strong>ğŸ‘ˆ</strong></a>
                
                
            </div>
            <div class="column"></div>
            <div class="column is-narrow paddingless">
                <a class="button is-large" href="#"><strong>ğŸ‘†</strong></a>
            </div>
            <div class="column"></div>
            <div class="column is-narrow paddingless">
                
                
                <a class="button is-large" href="https://jhandguy.github.io/posts/farewell-ecs-hello-eks/"><strong>ğŸ‘‰</strong></a>
                
                
            </div>
        </div>
        <div class="content has-text-centered">
            <p class="subtitle is-6">Powered by <a href="https://gohugo.io/">Hugo</a></p>
            <a href="https://bulma.io">
                <img src="/images/footer/made-with-bulma.png" alt="Made with Bulma" width="128" height="24">
            </a>
        </div>
    </div>
</footer>

</html>
