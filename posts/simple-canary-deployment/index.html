<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Canary Deployment in Kubernetes (Part 1) â€” Simple Canary Deployment using Ingress NGINX</title>
    <link rel="stylesheet" href="/css/bulma.min.css">
    <link rel="stylesheet" href="/css/custom.css">
</head>

<body>
<nav class="navbar">
    <div class="navbar-brand">
        <a class="navbar-item" href="/">
            Home
        </a>

        <div class="navbar-item">
            <a class="button is-link" href="/about">
                <strong>About me</strong>
            </a>
        </div>
    </div>
</nav>

<section class="section">
    <div class="container is-max-desktop">
        <div class="content">
            <p class="title is-spaced">Canary Deployment in Kubernetes (Part 1) â€” Simple Canary Deployment using Ingress NGINX</p>
            
            
            <div class="box">
                <p class="subtitle">Table of Contents</p>
                <nav id="TableOfContents">
  <ul>
    <li><a href="#requirements">Requirements</a></li>
    <li><a href="#creating-kind-cluster">Creating Kind Cluster</a></li>
    <li><a href="#installing-nginx-ingress-controller">Installing NGINX Ingress Controller</a></li>
    <li><a href="#configuring-ingress-canary-annotations">Configuring Ingress Canary Annotations</a></li>
    <li><a href="#rolling-out-canary-deployments-incrementally">Rolling-out Canary Deployments Incrementally</a>
      <ul>
        <li><a href="#load-testing-with-k6">Load Testing with k6</a></li>
      </ul>
    </li>
    <li><a href="#wrapping-up">Wrapping up</a></li>
  </ul>
</nav>
            </div>
            
            
        </div>
    </div>
    <div class="container is-max-desktop mt-6">
        <div class="content has-text-justified-tablet">
            <p>Deploying to production in Kubernetes can be quite stressful. Even after meaningful and reliable automated tests have successfully passed, there is still room for things to go wrong and lead to a nasty incident when pressing the final button.</p>
<p>Thankfully, Kubernetes is made to be resilient to this kind of scenario, and rolling back is a no-brainer. But still, rolling back means that, at least for some time, <strong>all of the users</strong> were negatively impacted by the faulty changeâ€¦</p>
<p>What if we could smoke test our change in production <strong>before</strong> it actually hits real users? What if we could roll out a change incrementally to <strong>some users</strong> instead of all of them at once? What if we could detect a faulty deployment and roll it back automatically?<br>
Well, that, my friend, is what Canary Deployment is all about!</p>
<blockquote>
<p>Minimizing the impact on real users while deploying a risky change to production.</p>
</blockquote>
<p>ğŸ¬ Hi there, Iâ€™m Jean!</p>
<p>In this 3 parts series, weâ€™re going to explore several ways to do Canary Deployment in Kubernetes, and the first one isâ€¦<br>
ğŸ¥<br>
â€¦ using <strong>Ingress NGINX</strong>! ğŸŠ</p>
<h2 id="requirements">Requirements</h2>
<hr>
<p>Before we start, make sure you have the following tools installed:</p>
<ul>
<li><a href="https://kind.sigs.k8s.io/docs/user/quick-start/#installation">Kind</a></li>
<li><a href="https://kubernetes.io/docs/tasks/tools/">Kubectl</a></li>
<li><a href="https://helm.sh/docs/intro/install/">Helm</a></li>
<li><a href="https://k6.io/docs/getting-started/installation/">K6</a></li>
</ul>
<blockquote>
<p><em>Note: for MacOS users or Linux users using Homebrew, simply run:</em><br>
<code>brew install kind kubectl helm k6</code></p>
</blockquote>
<p>All set? Letâ€™s go! ğŸ</p>
<h2 id="creating-kind-cluster">Creating Kind Cluster</h2>
<hr>
<p><a href="https://kind.sigs.k8s.io/">Kind</a> is a tool for running local Kubernetes clusters using Docker container â€œnodesâ€.
It was primarily designed for testing Kubernetes itself, but may be used for local development or CI.</p>
<p>I donâ€™t expect you to have a demo project in handy, so <a href="https://github.com/jhandguy/canary-deployment">I built one</a> for you.</p>
<pre><code class="language-shell">git clone https://github.com/jhandguy/canary-deployment.git
cd canary-deployment
</code></pre>
<p>Alright, let&rsquo;s spin up our Kind cluster! ğŸš€</p>
<pre><code class="language-shell">âœ kind create cluster --image kindest/node:v1.27.3 --config=kind/cluster.yaml
Creating cluster &quot;kind&quot; ...
 âœ“ Ensuring node image (kindest/node:v1.27.3) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦
 âœ“ Writing configuration ğŸ“œ
 âœ“ Starting control-plane ğŸ•¹ï¸
 âœ“ Installing CNI ğŸ”Œ
 âœ“ Installing StorageClass ğŸ’¾
Set kubectl context to &quot;kind-kind&quot;
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community ğŸ™‚
</code></pre>
<h2 id="installing-nginx-ingress-controller">Installing NGINX Ingress Controller</h2>
<hr>
<p><a href="https://github.com/kubernetes/ingress-nginx">NGINX Ingress Controller</a> is one of the <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/#additional-controllers">many available Kubernetes Ingress Controllers</a>, which acts as a load balancer and satisfies routing rules specified in <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/#what-is-ingress">Ingress</a> resources, using the <a href="https://nginx.org/en/">NGINX reverse proxy</a>.</p>
<p>NGINX Ingress Controller can be installed via its <a href="https://github.com/kubernetes/ingress-nginx/tree/main/charts/ingress-nginx">Helm chart</a>.</p>
<pre><code class="language-shell">helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install ingress-nginx/ingress-nginx --name-template ingress-nginx --create-namespace -n ingress-nginx --values kind/ingress-nginx-values.yaml --version 4.8.3 --wait
</code></pre>
<p>Now, if everything goes according to plan, you should be able to see the <strong>ingress-nginx-controller</strong> Deployment running.</p>
<pre><code class="language-shell">âœ kubectl get deploy -n ingress-nginx
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
ingress-nginx-controller   1/1     1            1           4m35s
</code></pre>
<h2 id="configuring-ingress-canary-annotations">Configuring Ingress Canary Annotations</h2>
<hr>
<p>Now that our NGINX Ingress Controller is up and running, letâ€™s get into the thick of it, shall we? ğŸ§</p>
<pre><code class="language-shell">helm install sample-app/helm-charts/ingress-nginx --name-template sample-app --create-namespace -n sample-app --wait
</code></pre>
<p>If everything goes fine, you should eventually see two Deployments with the READY state.</p>
<pre><code class="language-shell">âœ kubectl get deploy -n sample-app
NAME                READY   UP-TO-DATE   AVAILABLE   AGE
sample-app          1/1     1            1           100s
sample-app-canary   1/1     1            1           100s
</code></pre>
<p>Alright, letâ€™s take a look at whatâ€™s under all this!</p>
<pre><code class="language-shell">âœ ls -1 sample-app/helm-charts/ingress-nginx/templates
canary
deployment.yaml
ingress.yaml
service.yaml
serviceaccount.yaml

âœ ls -1 sample-app/helm-charts/ingress-nginx/templates/canary
deployment.yaml
ingress.yaml
service.yaml
</code></pre>
<p>As you can see, most of the resources have been duplicated, except for the <code>serviceaccount.yaml</code>:</p>
<ul>
<li>The <code>deployment.yaml</code> and the <code>canary/deployment.yaml</code> are strictly the same, apart from the name and the image tag.</li>
<li>The <code>service.yaml</code> and the <code>canary/service.yaml</code> are also very much the same, except for the name and the label selector.</li>
</ul>
<p>This is actually for a simple reason: in the end, the stable and the canary deployments are meant to be very much alike, apart from the image built inside the container, exactly like for a <a href="https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment">blue/green deployment</a>.</p>
<p>Now, the <code>ingress.yaml</code> and the <code>canary/ingress.yaml</code> are similar, but not very much the same though: youâ€™ll notice some extra <a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/">annotations</a> in the <code>canary/ingress.yaml</code>.</p>
<pre><code class="language-yaml">---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  ...
  annotations:
    ...
    nginx.ingress.kubernetes.io/canary: &quot;true&quot;
    nginx.ingress.kubernetes.io/canary-weight: &quot;{{ .Values.canary.weight }}&quot;
    nginx.ingress.kubernetes.io/canary-by-header: &quot;X-Canary&quot;
...
</code></pre>
<blockquote>
<p>This is where the magic happens! ğŸª„</p>
</blockquote>
<p>Letâ€™s dive into each of these <a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/">annotations</a> real quick:</p>
<ul>
<li><strong><a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#canary">nginx.ingress.kubernetes.io/canary</a></strong><br>
When set to <code>&quot;true&quot;</code>, this will let the Ingress Controller know that this is the Ingress routing traffic to the canary Deployment.</li>
<li><strong><a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#canary">nginx.ingress.kubernetes.io/canary-weight</a></strong><br>
When given a value, this will tell the Ingress Controller how to split traffic between the stable and the canary Deployments.
For instance, a weight of <code>50</code> would result in a 50/50 split.</li>
<li><strong><a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#canary">nginx.ingress.kubernetes.io/canary-by-header</a></strong><br>
When given a key, this will allow us to force a request into hitting the canary or the stable deployment, no matter the <code>canary-weight</code>.
By using the header value <code>always</code>, the request will always land in the canary Deployment, and when using the value <code>never</code>, the request will always land in the stable one.</li>
</ul>
<p>Right now, the <code>canary-weight</code> is <code>0</code> and the <code>canary-by-header</code> is <code>X-Canary</code>. This means that normal requests will never land in the canary Deployment unless a header <code>X-Canary: always</code> is passed to the request.</p>
<pre><code class="language-shell">âœ kubectl describe ingress sample-app-canary -n sample-app
...
Annotations:  ...
              nginx.ingress.kubernetes.io/canary: true
              nginx.ingress.kubernetes.io/canary-by-header: X-Canary
              nginx.ingress.kubernetes.io/canary-weight: 0
...
</code></pre>
<p>Letâ€™s give it a try!</p>
<pre><code class="language-shell">curl localhost/success -H &quot;Host: sample.app&quot;
</code></pre>
<p>As you can see, no matter how many times you run this command, the <code>pod</code> will always be the same. In fact, this is the <code>stable</code> pod.</p>
<pre><code class="language-shell">âœ curl localhost/success -H &quot;Host: sample.app&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-6bd9dc6d5d-jstn2&quot;,&quot;deployment&quot;:&quot;stable&quot;}

âœ curl localhost/success -H &quot;Host: sample.app&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-6bd9dc6d5d-jstn2&quot;,&quot;deployment&quot;:&quot;stable&quot;}

âœ curl localhost/success -H &quot;Host: sample.app&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-6bd9dc6d5d-jstn2&quot;,&quot;deployment&quot;:&quot;stable&quot;}
</code></pre>
<p>This is due to the fact that the current <code>canary-weight</code> is <code>0</code> thus 100% of the traffic will normally go to the <code>stable</code> Deployment.</p>
<p>Now letâ€™s try with the <code>X-Canary: always</code> header!</p>
<pre><code class="language-shell">curl localhost/success -H &quot;Host: sample.app&quot; -H &quot;X-Canary: always&quot;
</code></pre>
<p>Aha! We are now consistently hitting the <code>canary</code> pod.</p>
<pre><code class="language-shell">âœ curl localhost/success -H &quot;Host: sample.app&quot; -H &quot;X-Canary: always&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-canary-b559b9d75-gfvxp&quot;,&quot;deployment&quot;:&quot;canary&quot;}

âœ curl localhost/success -H &quot;Host: sample.app&quot; -H &quot;X-Canary: always&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-canary-b559b9d75-gfvxp&quot;,&quot;deployment&quot;:&quot;canary&quot;}

âœ curl localhost/success -H &quot;Host: sample.app&quot; -H &quot;X-Canary: always&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-canary-b559b9d75-gfvxp&quot;,&quot;deployment&quot;:&quot;canary&quot;}
</code></pre>
<p>Did you pay attention to what we just did? ğŸ˜‰<br>
This has a name: <strong>Smoke Testing</strong>! ğŸ”¥</p>
<p>Thatâ€™s right, we just smoke-tested a change, in production, while isolating it from the rest of the users as normal requests are routed to the <code>stable</code> Deployment thanks to the <code>canary-weight</code>. However, we bypassed that during Smoke Testing by utilizing the <code>canary-by-header</code> to force the request into hitting the <code>canary</code> Deployment.<br>
Isnâ€™t that awesome?! No more panic attacks when smoke tests fail on Canary, your users arenâ€™t affected. ğŸ˜Œ</p>
<h2 id="rolling-out-canary-deployments-incrementally">Rolling-out Canary Deployments Incrementally</h2>
<hr>
<p>So we have solved one problem, yet one remains: How do we expose a change to our real users incrementally, to minimize the impact if something goes south?</p>
<p>Well, youâ€™ve probably guessed it, <code>canary-weight</code> to the rescue! ğŸš€</p>
<p>We can simply slowly increase the <code>canary-weight</code> in order to let <strong>some</strong> users being routed to the <code>canary</code> Deployment. Letâ€™s give it a try!</p>
<pre><code class="language-shell">helm upgrade sample-app sample-app/helm-charts/ingress-nginx -n sample-app --reuse-values --set canary.weight=50 --wait
</code></pre>
<p>Letâ€™s verify that our <code>canary</code> Ingress now has a <code>canary-weight</code> of <code>50</code>!</p>
<pre><code class="language-shell">âœ kubectl describe ingress sample-app-canary -n sample-app
...
Annotations:  ...
              nginx.ingress.kubernetes.io/canary: true
              nginx.ingress.kubernetes.io/canary-by-header: X-Canary
              nginx.ingress.kubernetes.io/canary-weight: 50
...
</code></pre>
<p>All good, letâ€™s test it out!</p>
<pre><code class="language-shell">curl localhost/success -H &quot;Host: sample.app&quot;
</code></pre>
<p>As you can see, traffic is now equally split between the <code>stable</code> and <code>canary</code> Deployments.</p>
<pre><code class="language-shell">âœ curl localhost/success -H &quot;Host: sample.app&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-6bd9dc6d5d-jstn2&quot;,&quot;deployment&quot;:&quot;stable&quot;}

âœ curl localhost/success -H &quot;Host: sample.app&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-canary-5754f4bbc7-lvthj&quot;,&quot;deployment&quot;:&quot;canary&quot;}

âœ curl localhost/success -H &quot;Host: sample.app&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-6bd9dc6d5d-jstn2&quot;,&quot;deployment&quot;:&quot;stable&quot;}

âœ curl localhost/success -H &quot;Host: sample.app&quot;
{&quot;node&quot;:&quot;kind-control-plane&quot;,&quot;namespace&quot;:&quot;sample-app&quot;,&quot;pod&quot;:&quot;sample-app-canary-5754f4bbc7-lvthj&quot;,&quot;deployment&quot;:&quot;canary&quot;}
</code></pre>
<h3 id="load-testing-with-k6">Load Testing with k6</h3>
<hr>
<p>Now weâ€™ve made a few requests, letâ€™s see how it behaves under load and whether or not it indeed guarantees about 50% traffic distribution!</p>
<p>For Load Testing, I really recommend <a href="https://k6.io/docs/">k6</a> from the Grafana Labs team. It is a dead-simple yet super powerful tool with very extensive documentation.</p>
<p>See for yourself!</p>
<pre><code class="language-shell">k6 run k6/script.js
</code></pre>
<p>After about 1 minute, k6 should be done executing the load test and show you the results.</p>
<pre><code class="language-shell">          /\      |â€¾â€¾| /â€¾â€¾/   /â€¾â€¾/
     /\  /  \     |  |/  /   /  /
    /  \/    \    |     (   /   â€¾â€¾\
   /          \   |  |\  \ |  (â€¾)  |
  / __________ \  |__| \__\ \_____/ .io

  execution: local
     script: k6/script.js
     output: -

  scenarios: (100.00%) 1 scenario, 20 max VUs, 1m30s max duration (incl. graceful stop):
           * load: Up to 20.00 iterations/s for 1m0s over 2 stages (maxVUs: 20, gracefulStop: 30s)


     âœ“ status code is 200
     âœ“ node is kind-control-plane
     âœ“ namespace is sample-app
     âœ“ pod is sample-app-*
     âœ“ deployment is stable or canary

   âœ“ checks.........................: 100.00% âœ“ 3095      âœ— 0
     data_received..................: 160 kB  2.7 kB/s
     data_sent......................: 71 kB   1.2 kB/s
     http_req_blocked...............: avg=48.21Âµs  min=3Âµs    med=18Âµs   max=2.38ms  p(90)=23Âµs   p(95)=30.09Âµs
     http_req_connecting............: avg=24.56Âµs  min=0s     med=0s     max=1.48ms  p(90)=0s     p(95)=0s
   âœ“ http_req_duration..............: avg=4.87ms   min=800Âµs  med=4.24ms max=34.52ms p(90)=7.85ms p(95)=9.88ms
       { expected_response:true }...: avg=4.87ms   min=800Âµs  med=4.24ms max=34.52ms p(90)=7.85ms p(95)=9.88ms
     http_req_failed................: 0.00%   âœ“ 0         âœ— 619
     http_req_rate..................: 50.00%  âœ“ 619       âœ— 619
     âœ“ { deployment:canary }........: 47.65%  âœ“ 295       âœ— 324
     âœ“ { deployment:stable }........: 52.34%  âœ“ 324       âœ— 295
     http_req_receiving.............: avg=132.17Âµs min=24Âµs   med=136Âµs  max=610Âµs   p(90)=179Âµs  p(95)=213.09Âµs
     http_req_sending...............: avg=70.69Âµs  min=15Âµs   med=72Âµs   max=736Âµs   p(90)=94.2Âµs p(95)=101Âµs
     http_req_tls_handshaking.......: avg=0s       min=0s     med=0s     max=0s      p(90)=0s     p(95)=0s
     http_req_waiting...............: avg=4.67ms   min=719Âµs  med=4.02ms max=34.2ms  p(90)=7.64ms p(95)=9.65ms
     http_reqs......................: 619     10.316511/s
     iteration_duration.............: avg=5.59ms   min=1.08ms med=5.02ms max=41.22ms p(90)=8.68ms p(95)=10.52ms
     iterations.....................: 619     10.316511/s
     vus............................: 0       min=0       max=0
     vus_max........................: 20      min=20      max=20


running (1m00.0s), 00/20 VUs, 619 complete and 0 interrupted iterations
load âœ“ [======================================] 00/20 VUs  1m0s  00.71 iters/s
</code></pre>
<p>That sounds about right!<br>
Out of 619 requests, 295 (48%) were served by the <code>canary</code> Deployment while 324 (52%) were served by the <code>stable</code> one. Pretty good!</p>
<h2 id="wrapping-up">Wrapping up</h2>
<hr>
<p>Thatâ€™s it! You can now delete your Kind cluster.</p>
<pre><code class="language-shell">kind delete cluster
</code></pre>
<p>To summarize, using Ingress NGINX we were able to:</p>
<ul>
<li>Smoke test our change in complete isolation from the rest of the users;</li>
<li>Incrementally expose our change to <strong>some</strong> users to minimize risk.</li>
</ul>
<p>Was it worth it? Did that help you understand how to implement Canary Deployment in Kubernetes using Ingress NGINX?</p>
<p>If so, follow me on <a href="https://twitter.com/jhandguy">Twitter</a>, Iâ€™ll be happy to answer any of your questions and youâ€™ll be the first one to know when a new article comes out! ğŸ‘Œ</p>
<p>See you next week, for Part 2 of my series <strong>Canary Deployment in Kubernetes</strong>!</p>
<p>Bye-bye! ğŸ‘‹</p>

        </div>
    </div>
</section>

</body>
<footer>
    <div class="footer pt-3 has-background-black-bis">
        <div class="container pb-6 has-text-centered is-mobile columns">
            <div class="column is-narrow paddingless">
                
                
                <a class="button is-large" href="https://jhandguy.github.io/posts/path-to-cicd-nirvana-ios/"><strong>ğŸ‘ˆ</strong></a>
                
                
            </div>
            <div class="column"></div>
            <div class="column is-narrow paddingless">
                <a class="button is-large" href="#"><strong>ğŸ‘†</strong></a>
            </div>
            <div class="column"></div>
            <div class="column is-narrow paddingless">
                
                
                <a class="button is-large" href="https://jhandguy.github.io/posts/automated-canary-deployment/"><strong>ğŸ‘‰</strong></a>
                
                
            </div>
        </div>
        <div class="content has-text-centered">
            <p class="subtitle is-6">Powered by <a href="https://gohugo.io/">Hugo</a></p>
            <a href="https://bulma.io">
                <img src="/images/footer/made-with-bulma.png" alt="Made with Bulma" width="128" height="24">
            </a>
        </div>
    </div>
</footer>

</html>
